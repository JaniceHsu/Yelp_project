{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from variousLearnersOverall import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [(0, 'funny'), (1, 'user_id'), (2, 'review_id'), \n",
    "# (3, 'text'), (4, 'business_id'), (5, 'stars'), \n",
    "# (6, 'date'), (7, 'useful'), (8, 'type'), \n",
    "# (9, 'cool'), (10, 'food'), (11, 'price'), \n",
    "# (12, 'service')]\n",
    "def separateTextTarget(reader):\n",
    "    docs = []\n",
    "    t1 = []    \n",
    "    t2 = []\n",
    "    t3 = []\n",
    "    for row in reader:\n",
    "        break\n",
    "    for row in reader:\n",
    "        docs.append(row[3])\n",
    "        t1.append(row[10])\n",
    "        t2.append(row[11])\n",
    "        t3.append(row[12])\n",
    "    return (docs, t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRows(reader):\n",
    "    docs = []\n",
    "    for row in reader:\n",
    "        break\n",
    "    for row in reader:\n",
    "        docs.append([row[3], row[10], row[11], row[12]])\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = r\"labeledChineseReview\"\n",
    "docs = []\n",
    "for i in range(1,6):\n",
    "    fname = fn+str(i)+\".csv\"\n",
    "    f= open(fname, 'r', encoding = 'utf8')\n",
    "    reader = csv.reader(f)\n",
    "    docs.extend(getRows(reader))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "tfood = []\n",
    "tprice = []\n",
    "tservice = []\n",
    "for a,b,c,d in docs:\n",
    "    text.append(a)\n",
    "    tfood.append(b)\n",
    "    tprice.append(c)\n",
    "    tservice.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(text)\n",
    "temp = []\n",
    "for i in text:\n",
    "    if i == '':\n",
    "        temp.append('3')\n",
    "    else:\n",
    "        temp.append(i)\n",
    "text = temp\n",
    "temp = []\n",
    "for i in tfood:\n",
    "    if i == '':\n",
    "        temp.append('3')\n",
    "    else:\n",
    "        temp.append(i)\n",
    "tfood = temp\n",
    "trtext = text[:4*n//5]\n",
    "trfood = tfood[:4*n//5]\n",
    "trprice = tprice[:4*n//5]\n",
    "trservice = tservice[:4*n//5]\n",
    "tetext = text[4*n//5:]\n",
    "tefood = tfood[4*n//5:]\n",
    "teprice = tprice[4*n//5:]\n",
    "teservice = tservice[4*n//5:]\n",
    "\n",
    "train_target = trfood\n",
    "test_target = tefood\n",
    "train_docs = trtext\n",
    "test_docs = tetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Function: extract_text_features()\n"
     ]
    }
   ],
   "source": [
    "X_train_counts, X_train_tfidf, X_test_counts, X_test_tfidf = extract_text_features(train_docs,  test_docs,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_multNB = fit_and_predict_multinomialNB(X_train_tfidf, train_target, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've recently become a regular to this restaurant  -> 2, 1\n",
      "Went to actually go to Aloha Kitchen with my Frien -> 2, 2\n",
      "Thanks for giving me two pieces of shrimp and thre -> 2, 3\n",
      "My experience was poor, the miso soup was cold. Th -> 2, 0\n",
      "One of the biggest scams in LV, you are better off -> 2, 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc, p, i in zip(tetext, predicted_multNB, range(5)):\n",
    "    print('{} -> {}, {}'.format(doc[:50], p, tefood[i]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      "['2' '2' '2' '2' '2' '2' '1' '2' '1' '2' '2' '2' '2' '2' '2' '2' '1' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '1' '2' '2' '2' '1' '2' '2']\n",
      "['2' '2' '3' '2' '2' '2' '2' '2' '1' '1' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '1' '2' '1' '2' '2']\n",
      "['2' '0' '0' '2' '2' '2' '2' '1' '0' '2' '0' '2' '2' '2' '2' '2' '2' '2'\n",
      " '1' '0' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '0' '0' '2' '0' '0']\n",
      "['2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2']\n"
     ]
    }
   ],
   "source": [
    "    predicted_bernNB = fit_and_predict_BernoulliNB(X_train_tfidf, train_target, X_test_tfidf)\n",
    "    predicted_LR = fit_and_predict_LR(X_train_tfidf, train_target, X_test_tfidf)\n",
    "    predicted_LR = fit_and_predict_LR(X_train_counts, train_target, X_test_counts)\n",
    "    K=3\n",
    "    predicted_KNN = fit_and_predict_KNN(X_train_tfidf, train_target, X_test_tfidf, K)\n",
    "    print(predicted_bernNB)\n",
    "    print(predicted_LR)\n",
    "    print(predicted_KNN)\n",
    "    print(predicted_multNB)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predicted_bernNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Predicted labels with multinomial NB classifier:\n",
      "I've recently become a regular to this restaurant  -> 2, 1\n",
      "Went to actually go to Aloha Kitchen with my Frien -> 2, 2\n",
      "Thanks for giving me two pieces of shrimp and thre -> 2, 3\n",
      "My experience was poor, the miso soup was cold. Th -> 2, 0\n",
      "One of the biggest scams in LV, you are better off -> 2, 3\n",
      "\n",
      "#####Predicted labels with Bernoulli NB classifier:\n",
      "I've recently become a regular to this restaurant  -> 2, 1\n",
      "Went to actually go to Aloha Kitchen with my Frien -> 2, 2\n",
      "Thanks for giving me two pieces of shrimp and thre -> 2, 3\n",
      "My experience was poor, the miso soup was cold. Th -> 2, 0\n",
      "One of the biggest scams in LV, you are better off -> 2, 3\n",
      "\n",
      "####Predicted labels with kNN classifier:\n",
      "I've recently become a regular to this restaurant  -> 2, 1\n",
      "Went to actually go to Aloha Kitchen with my Frien -> 0, 2\n",
      "Thanks for giving me two pieces of shrimp and thre -> 0, 3\n",
      "My experience was poor, the miso soup was cold. Th -> 2, 0\n",
      "One of the biggest scams in LV, you are better off -> 2, 3\n",
      "\n",
      "####Predicted labels with logistic classifier:\n",
      "I've recently become a regular to this restaurant  -> 2, 1\n",
      "Went to actually go to Aloha Kitchen with my Frien -> 2, 2\n",
      "Thanks for giving me two pieces of shrimp and thre -> 3, 3\n",
      "My experience was poor, the miso soup was cold. Th -> 2, 0\n",
      "One of the biggest scams in LV, you are better off -> 2, 3\n",
      "\n",
      "\n",
      "test_classifiers(twenty_train, twenty_test, 1 [min_docs])\n",
      " Function: extract_text_features()\n",
      "Number of (training) documents = 140\n",
      "Vocabulary size = 2087\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      "Accuracy with multinomial naive Bayes: 0.528\n",
      "Accuracy with Bernoulli naive Bayes: 0.556\n",
      "Accuracy with logistic regression: 0.528\n",
      "Accuracy with kNN, k=3 classifier: 0.500\n",
      "Accuracy with kNN, k=5 classifier: 0.639\n",
      "\n",
      "test_classifiers(twenty_train, twenty_test, 3 [min_docs])\n",
      " Function: extract_text_features()\n",
      "Number of (training) documents = 140\n",
      "Vocabulary size = 548\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      "Accuracy with multinomial naive Bayes: 0.528\n",
      "Accuracy with Bernoulli naive Bayes: 0.583\n",
      "Accuracy with logistic regression: 0.500\n",
      "Accuracy with kNN, k=3 classifier: 0.444\n",
      "Accuracy with kNN, k=5 classifier: 0.639\n",
      "\n",
      "test_classifiers(twenty_train, twenty_test, 5 [min_docs])\n",
      " Function: extract_text_features()\n",
      "Number of (training) documents = 140\n",
      "Vocabulary size = 307\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      "Accuracy with multinomial naive Bayes: 0.528\n",
      "Accuracy with Bernoulli naive Bayes: 0.639\n",
      "Accuracy with logistic regression: 0.556\n",
      "Accuracy with kNN, k=3 classifier: 0.444\n",
      "Accuracy with kNN, k=5 classifier: 0.528\n",
      "\n",
      "test_classifiers(twenty_train, twenty_test, 10 [min_docs])\n",
      " Function: extract_text_features()\n",
      "Number of (training) documents = 140\n",
      "Vocabulary size = 108\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      "Accuracy with multinomial naive Bayes: 0.528\n",
      "Accuracy with Bernoulli naive Bayes: 0.583\n",
      "Accuracy with logistic regression: 0.500\n",
      "Accuracy with kNN, k=3 classifier: 0.361\n",
      "Accuracy with kNN, k=5 classifier: 0.417\n",
      "\n",
      "test_classifiers(twenty_train, twenty_test, 20 [min_docs])\n",
      " Function: extract_text_features()\n",
      "Number of (training) documents = 140\n",
      "Vocabulary size = 31\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      " Student: Janice_Hsu,   Function: fit_and_predict_LR()\n",
      "Accuracy with multinomial naive Bayes: 0.528\n",
      "Accuracy with Bernoulli naive Bayes: 0.611\n",
      "Accuracy with logistic regression: 0.472\n",
      "Accuracy with kNN, k=3 classifier: 0.333\n",
      "Accuracy with kNN, k=5 classifier: 0.444\n"
     ]
    }
   ],
   "source": [
    "print('#####Predicted labels with multinomial NB classifier:') \n",
    "for doc, p, i in zip(test_docs, predicted_multNB, range(5)):\n",
    "    print('{} -> {}, {}'.format(doc[:50], p, test_target[i]))\n",
    "print()\n",
    "\n",
    "# # Bernoulli naive Bayes\n",
    "print('#####Predicted labels with Bernoulli NB classifier:') \n",
    "for doc, p, i in zip(test_docs, predicted_bernNB, range(5)):\n",
    "    print('{} -> {}, {}'.format(doc[:50], p, test_target[i]))\n",
    "print()\n",
    "\n",
    "\n",
    "# kNN\n",
    "print('####Predicted labels with kNN classifier:')\n",
    "for doc, p, i in zip(test_docs, predicted_KNN, range(5)):\n",
    "    print('{} -> {}, {}'.format(doc[:50], p, test_target[i]))\n",
    "print()\n",
    "#\n",
    "# Logistic Regression \n",
    "print('####Predicted labels with logistic classifier:')\n",
    "for doc, p, i in zip(test_docs, predicted_LR, range(5)):\n",
    "    print('{} -> {}, {}'.format(doc[:50], p, test_target[i]))\n",
    "print()\n",
    "\n",
    "for i in [1,3,5,10,20]:\n",
    "    print(\"\\ntest_classifiers(twenty_train, twenty_test, {} [min_docs])\".format(i))\n",
    "    test_classifiers(train_docs, train_target, test_docs, test_target, i, 3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "x  =nltk.FreqDist(test_target)\n",
    "x.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
